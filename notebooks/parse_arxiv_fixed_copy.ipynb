{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import urllib\n",
    "import time\n",
    "import feedparser\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph_adj_list(data, authors, adj_list=set(), seen=set(), weighted_adj_list=None):\n",
    "    all_author_pairs = [(min(a1, a2), max(a1, a2)) for (a1, a2) in itertools.combinations(authors, 2)]\n",
    "    all_author_pairs_set = set(all_author_pairs)\n",
    "    if weighted_adj_list is None:\n",
    "        weighted_adj_list = {}\n",
    "        for pair in all_author_pairs:\n",
    "            weighted_adj_list[pair] = 0\n",
    "    for entry in data:\n",
    "        paper_authors = entry[2]\n",
    "        author_pairs = [(min(a1, a2), max(a1, a2)) for (a1, a2) in itertools.combinations(paper_authors, 2)]\n",
    "        for ap in author_pairs:\n",
    "            if ap[0] in authors and ap[1] in authors:\n",
    "                if ap in all_author_pairs_set and ap not in seen:\n",
    "                    seen.add(ap)\n",
    "                    adj_list.add((ap[0], ap[1], entry[1]))\n",
    "                    weighted_adj_list[ap] += 1\n",
    "    return adj_list, weighted_adj_list, seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from http://export.arxiv.org/api_help/docs/user-manual.html\n",
    "\"\"\"\n",
    "\n",
    "# Base api query url\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "# base_url = 'http://export.arxiv.org/api/search_query=';\n",
    "\n",
    "# Search parameters\n",
    "category = 'astro-ph'\n",
    "search_query = 'cat:' + category # search for electron in all fields\n",
    "# start = 0                        # start at the first result\n",
    "# total_results = 100000            # want 20 total results\n",
    "# results_per_iteration = 5000     # 5 results at a time\n",
    "\n",
    "start = 0                        # start at the first result\n",
    "total_results = 100000            # want 20 total results\n",
    "results_per_iteration = 5000     # 5 results at a time\n",
    "\n",
    "\n",
    "wait_time = 3                    # number of seconds to wait beetween calls\n",
    "\n",
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print 'Searching arXiv for %s' % search_query\n",
    "\n",
    "# with open(category + \".txt\", \"w\") as f:\n",
    "\n",
    "#     for i in range(start,total_results,results_per_iteration):\n",
    "#         print \"Results %i - %i\" % (i,i+results_per_iteration)\n",
    "#         query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "#                                                              i,\n",
    "#                                                             results_per_iteration)\n",
    "#         # perform a GET request using the base_url and query\n",
    "#         response = urllib.urlopen(base_url+query).read()\n",
    "\n",
    "#         # parse the response using feedparser\n",
    "#         feed = feedparser.parse(response)\n",
    "\n",
    "#         # Run through each entry, and print out information\n",
    "#         for entry in feed.entries:\n",
    "#             title = entry.title.encode('utf-8').replace(\"\\n\", \"\")\n",
    "#             year = entry.published_parsed[0]\n",
    "#             authors = tuple([str(author['name'].encode('utf-8')) for author in entry.authors])\n",
    "#             entries.append((title, year, authors))\n",
    "\n",
    "#             f.write(title + \",\" + str(year) + \",\" + \"|\".join(authors) + \"\\n\")\n",
    "\n",
    "#         print 'Sleeping for %i seconds' % wait_time \n",
    "#         time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle.dump(entries, open(category + '_entries.pkl', 'wb'))\n",
    "entries = pickle.load(open(category + '_entries.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1994: 0,\n",
       " 1995: 0,\n",
       " 1996: 1049,\n",
       " 1997: 1357,\n",
       " 1998: 4394,\n",
       " 1999: 5274,\n",
       " 2000: 5913,\n",
       " 2001: 4013,\n",
       " 2002: 0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_by_yr = {}\n",
    "for year in range(1994, 2003):\n",
    "    entries_by_yr[year] = len(filter(lambda entry: entry[1] == year, entries))\n",
    "entries_by_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = set(str.split(\"#\".join([\"#\".join(entry[2]) for entry in entries]), \"#\"))\n",
    "years = set(entry[1] for entry in entries)\n",
    "\n",
    "entries_1996 = filter(lambda entry: entry[1] == 1996, entries)\n",
    "entries_1997 = filter(lambda entry: entry[1] == 1997, entries)\n",
    "entries_1998 = filter(lambda entry: entry[1] == 1998, entries)\n",
    "entries_1999 = filter(lambda entry: entry[1] == 1999, entries)\n",
    "entries_2000 = filter(lambda entry: entry[1] == 2000, entries)\n",
    "entries_2001 = filter(lambda entry: entry[1] == 2001, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = entries_1996 + entries_1997 + entries_1998 + entries_1999\n",
    "test = entries_2000 + entries_2001\n",
    "\n",
    "all_authors_in_train = {author:0 for author in authors}\n",
    "all_authors_in_test = {author:0 for author in authors}\n",
    "\n",
    "datasets = {\"train\": train, \"test\": test}\n",
    "for name, dataset in datasets.iteritems():\n",
    "    for entry in dataset:\n",
    "        paper_authors = entry[2]\n",
    "        for author in paper_authors:\n",
    "            if name == \"train\":\n",
    "                all_authors_in_train[author] += 1 \n",
    "            else:\n",
    "                all_authors_in_test[author] += 1\n",
    "                \n",
    "# Core is subset of authors who have written at least 3 papers during training period\n",
    "authors_in_train = set([k for k, v in all_authors_in_train.iteritems() if v > 2])\n",
    "authors_in_test = set([k for k, v in all_authors_in_test.iteritems() if v > 2])\n",
    "authors_train_dict = [v for k, v in all_authors_in_train.iteritems() if v > 2]\n",
    "authors_test_dict = [v for k, v in all_authors_in_train.iteritems() if v > 2]\n",
    "authors = sorted(list(authors_in_train.intersection(authors_in_test)))\n",
    "authors = filter(lambda author: len(author) > 3, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_adj_list_names, weighted_train_adj_list_names, seen = create_graph_adj_list(train, authors)\n",
    "test_adj_list_names, weighted_test_adj_list_names, _ = \\\n",
    "                        create_graph_adj_list(test, authors, adj_list=deepcopy(train_adj_list_names),\n",
    "                        weighted_adj_list = deepcopy(weighted_train_adj_list_names), seen=seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entries_by_yr = {}\n",
    "for year in range(1994, 2003):\n",
    "    entries_by_yr[year] = set(filter(lambda entry: entry[2] == year, train_adj_list))\n",
    "    entries_by_yr[year] = set([tup[0:2] for tup in entries_by_yr[year]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_ind = {authors[i]:i for i in range(len(authors))}\n",
    "train_adj_list = map(lambda pair: (author_ind[pair[0]], author_ind[pair[1]], pair[2]), train_adj_list_names)\n",
    "test_adj_list = map(lambda pair: (author_ind[pair[0]], author_ind[pair[1]], pair[2]), test_adj_list_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1994: 0,\n",
       " 1995: 0,\n",
       " 1996: 1358,\n",
       " 1997: 2250,\n",
       " 1998: 5716,\n",
       " 1999: 4751,\n",
       " 2000: 4889,\n",
       " 2001: 2948,\n",
       " 2002: 0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_by_yr = {}\n",
    "for year in range(1994, 2003):\n",
    "    entries_by_yr[year] = len(filter(lambda entry: entry[2] == year, test_adj_list))\n",
    "entries_by_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1994: 0,\n",
       " 1995: 0,\n",
       " 1996: 1358,\n",
       " 1997: 2250,\n",
       " 1998: 5716,\n",
       " 1999: 4751,\n",
       " 2000: 4889,\n",
       " 2001: 2948,\n",
       " 2002: 0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_by_yr = {}\n",
    "for year in range(1994, 2003):\n",
    "    entries_by_yr[year] = len(filter(lambda entry: entry[2] == year, test_adj_list))\n",
    "entries_by_yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([tup[:2] for tup in set(test_adj_list) - set(train_adj_list)]).intersection([tup[:2] for tup in train_adj_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14075"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7837"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_adj_list) - len(train_adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_adj_list = [tup[0:2] for tup in train_adj_list]\n",
    "test_adj_list = [tup[0:2] for tup in test_adj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(author_ind, open(category + '_author_ind.pkl', 'wb'))\n",
    "pickle.dump(train_adj_list, open(category + '_train_adj_list.pkl', 'wb'))\n",
    "pickle.dump(test_adj_list, open(category + '_test_adj_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(author_ind, open(category + '_author_ind.pkl', 'wb'))\n",
    "pickle.dump(train_adj_list, open(category + '_train_adj_list_with_year.pkl', 'wb'))\n",
    "pickle.dump(test_adj_list, open(category + '_test_adj_list_with_year.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interesting stats for the graph\n",
    "# Number of nodes: 2338\n",
    "# Number of edges in train: 11801, number of edges in test: 18558\n",
    "# Max number of edges: 2731953\n",
    "# Average weight on each edge without 0s: 3.21\n",
    "# Max weight on each edge is 41\n",
    "# Mean edges per person 5.86\n",
    "# Max edges per node 55 (publications per author)\n",
    "\n",
    "np.mean(filter(lambda x: x != 0, [v for k, v in weighted_test_adj_list_names.iteritems()]))\n",
    "max([v for k, v in weighted_test_adj_list_names.iteritems()])\n",
    "np.mean(authors_test_dict)\n",
    "max(authors_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(36, 36))\n",
    "train_graph = nx.Graph()\n",
    "for ind, author in author_ind.iteritems():\n",
    "    train_graph.add_node(ind)\n",
    "for e in train_adj_list:\n",
    "    train_graph.add_edge(e[0], e[1])\n",
    "pos = nx.layout.circular_layout(train_graph)\n",
    "edgewidths = 1.0\n",
    "edgecolors = \"blue\"\n",
    "nodesizes = 0.2\n",
    "\n",
    "nx.draw_networkx_edges(train_graph, pos, width=edgewidths,\n",
    "                                edge_color=edgecolors, alpha=0.1)\n",
    "\n",
    "nx.draw_networkx_nodes(train_graph, pos, node_size=nodesizes,\n",
    "                                linewidth=edgewidths,\n",
    "                                node_color=\"black\", alpha=1)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
