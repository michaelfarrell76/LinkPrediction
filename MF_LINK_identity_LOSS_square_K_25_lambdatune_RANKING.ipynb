{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import pickle\n",
    "import urllib\n",
    "import time\n",
    "import feedparser\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy.misc\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Category of papers\n",
    "category = 'data/astro-ph'\n",
    "\n",
    "# Metadata\n",
    "entries = pickle.load(open(category + '_entries.pkl', 'rb'))\n",
    "author_ind = pickle.load( open(category + '_author_ind.pkl', 'rb'))\n",
    "\n",
    "# List of edges in train/test graphs\n",
    "train_adj_list = pickle.load(open(category + '_train_adj_list.pkl', 'rb'))\n",
    "test_adj_list = pickle.load(open(category + '_test_adj_list.pkl', 'rb'))\n",
    "\n",
    "# List of edges with year added in train/test graphs\n",
    "train_adj_list_w_year = pickle.load( open( category + '_train_adj_list_with_year.pkl'))\n",
    "test_adj_list_w_year = pickle.load( open( category + '_test_adj_list_with_year.pkl'))\n",
    "\n",
    "# Number of authors\n",
    "num_authors = len(author_ind)\n",
    "\n",
    "# List of author ids\n",
    "authors = range(num_authors)\n",
    "\n",
    "# Edges\n",
    "pos_edges = set([(min(a1, a2), max(a1, a2)) for (a1, a2) in \\\n",
    "                 itertools.combinations(authors, 2)]) - set(train_adj_list)\n",
    "pred_edges = set(test_adj_list) - set(train_adj_list)\n",
    "\n",
    "# Years in the training set\n",
    "train_years = sorted(list(set(map(lambda x : x[2], train_adj_list_w_year))))\n",
    "\n",
    "# Years in the testing set\n",
    "test_years = sorted(list(set(map(lambda x : x[2], test_adj_list_w_year))))\n",
    "\n",
    "# All possible edges\n",
    "possible_edges = list(itertools.combinations(authors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the edges up by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges_by_year = {}\n",
    "for year in test_years:\n",
    "    edges_by_year[year] = map(lambda y: y[:2], filter(lambda x : x[2] == year, test_adj_list_w_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 1358)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1997, 2250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1998, 5716)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1999, 4751)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2000, 4889)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2001, 2948)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in test_years:\n",
    "    year, len(edges_by_year[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train years', [1996, 1997, 1998], 'validation years', 1999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_for_train = train_years[:3]\n",
    "valid_year = train_years[3]\n",
    "'train years', years_for_train, 'validation years', valid_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the set of edges in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = set()\n",
    "for year in years_for_train:\n",
    "    train = train.union(set(edges_by_year[year]))\n",
    "n_train = len(train)\n",
    "n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label all edges as 1 for edge and 0 for no edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = map(lambda x : int(x in train), possible_edges)\n",
    "zipped_train_input = zip(possible_edges, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o_minus = filter(lambda x : x[1] == 0, zipped_train_input)\n",
    "o_plus = filter(lambda x : x[1] == 1, zipped_train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set of new edges added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4751"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = set(edges_by_year[valid_year]).difference(train)\n",
    "n_valid = len(valid)\n",
    "n_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The set of labled edges to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "potential_new_edges = set(map(lambda  y : y[0], filter(lambda x: x[1] == 0, zipped_train_input)))\n",
    "zipped_valid_input = map(lambda x : (x, 1) if x in valid else (x,0), potential_new_edges)\n",
    "valid_no_edges = filter(lambda x: x[1] == 0, zipped_valid_input)\n",
    "valid_yes_edges = filter(lambda x: x[1] == 1, zipped_valid_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3272961"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zipped_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_plus = len(o_plus) \n",
    "n_min = len(o_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_min = len(o_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "900 * 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Link, Log Loss, No extrinsic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Avg Train Loss: 9.59296342104\n",
      "Avg Validation Loss: 9.59296460881\n",
      "Avg Score for missing edges: 7.25276932441 Avg Score for added edges: 7.2651791061\n",
      "Median Score for missing edges: 7.22039144971 Media Score for added edges: 7.23384270345\n",
      "Avg Difference: 0.0124097816925\n",
      "Median Difference: 0.0134512537407\n",
      "Accuracy on Top 4751 : 0.00105241001894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/900 [00:01<05:55,  2.52it/s]"
     ]
    }
   ],
   "source": [
    "VERBOSE = True\n",
    "ADD_LOG = True\n",
    "PLOT = True\n",
    "n_neg = 10000\n",
    "n_pos = 900\n",
    "\n",
    "if PLOT:\n",
    "    %matplotlib inline\n",
    "\n",
    "gammaU = 1e-3 # Learning rate for latent feature vectors\n",
    "gammaB = 1e-3 # Learning rate for node biases\n",
    "# lambdaU = 1e-1 # regularization parameter for latent feature vecotrs\n",
    "TOP_K = n_valid # K to use for top k accuracy\n",
    "N_EPOCH = 5 # Number of epochs to train\n",
    "link = lambda x : x # the link function mapping score to prediction\n",
    "link_name = 'identity'\n",
    "loss = lambda (p, t): (p - t)**2 # loss function takes in prediction and target and returns loss\n",
    "loss_name = 'squared'\n",
    "score = lambda i, j, ip, jp: np.dot(U[i], U[j]) + B[i] + B[j] -(np.dot(U[ip], U[jp]) + B[ip] + B[jp]) # Takes in two nodes and scores their probability of an edge\n",
    "score1 = lambda i, j : np.dot(U[i], U[j]) + B[i] + B[j]\n",
    "k = 25\n",
    "# k_vals = [5, 10, 25, 50, 75, 100] # Number of latent features\n",
    "lambdaU_vals = [1e2, 1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "results = {}\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "for lambdaU in lambdaU_vals:\n",
    "    U = np.random.rand(num_authors,k) # latent feature matrix\n",
    "    B = np.random.rand(num_authors) # Biases\n",
    "\n",
    "    # Holding the train/validation losses\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # Holds the average/medians prediction score for edges being added and not added\n",
    "    no_avgs = []\n",
    "    no_meds = []\n",
    "    yes_avgs = []\n",
    "    yes_meds = []\n",
    "\n",
    "    # Differences between yes_avgs and no_avgs, yes_meds and no_meds\n",
    "    diff_avgs = []\n",
    "    diff_meds = []\n",
    "\n",
    "    # Accuracy on TOP_K\n",
    "    topk_acc = []\n",
    "\n",
    "\n",
    "    def predict(vals):\n",
    "        '''\n",
    "            Give the zipped input, returned the prediction and target value in a \n",
    "            list of tuples\n",
    "\n",
    "            (pred, targ)\n",
    "        '''\n",
    "        return map(lambda ((i,j), t) : (link(score1(i, j)), t), vals)\n",
    "\n",
    "    def calc_loss(vals):\n",
    "        '''\n",
    "            Return the loss for the current state \n",
    "        '''\n",
    "        # Regularizer\n",
    "        reg_term = lambdaU * np.linalg.norm(U, ord='fro')\n",
    "\n",
    "        # Make predictions\n",
    "        preds = predict(vals)\n",
    "\n",
    "        # Calculate loss with regularization\n",
    "        loss_val = np.mean(map(loss, preds)) + reg_term\n",
    "\n",
    "        if ADD_LOG:\n",
    "            loss_val = np.log(loss_val)\n",
    "        return loss_val\n",
    "\n",
    "    def top_acc(vals):\n",
    "        '''\n",
    "            Determine our TOP_K rated edges and see if they are in the set\n",
    "            of edges that were added in the validations et\n",
    "        '''\n",
    "        predictions = predict(vals)\n",
    "\n",
    "        # Sort predictions \n",
    "        sorted_scores = sorted(predictions, key= lambda  x: x[0], reverse=True)\n",
    "\n",
    "        # Sett how many of the top predictions have an edge\n",
    "        return len(filter(lambda x : x[1] == 1, sorted_scores[:TOP_K])) / float(TOP_K)\n",
    "\n",
    "    def print_status(epoch, verbose = VERBOSE):\n",
    "        '''\n",
    "            Prints the current status of the SGD operation\n",
    "        '''\n",
    "        if VERBOSE: print 'EPOCH', epoch\n",
    "\n",
    "        train_losses.append(calc_loss(zipped_train_input))\n",
    "        if VERBOSE: print 'Avg Train Loss:',train_losses[epoch]\n",
    "\n",
    "        valid_losses.append(calc_loss(zipped_valid_input))\n",
    "        if VERBOSE: print 'Avg Validation Loss:', valid_losses[epoch]\n",
    "\n",
    "        no_preds =  map(lambda x : x[0], predict(valid_no_edges))\n",
    "        no_avgs.append(np.mean(no_preds))\n",
    "        no_meds.append(np.median(no_preds))\n",
    "\n",
    "        yes_preds = map(lambda x : x[0],predict(valid_yes_edges))\n",
    "        yes_avgs.append(np.mean(yes_preds))\n",
    "        yes_meds.append(np.median(yes_preds))\n",
    "        if VERBOSE: print 'Avg Score for missing edges:', no_avgs[epoch], 'Avg Score for added edges:', yes_avgs[epoch]\n",
    "        if VERBOSE: print 'Median Score for missing edges:', no_meds[epoch], 'Media Score for added edges:', yes_meds[epoch]\n",
    "\n",
    "        diff_avgs.append(yes_avgs[epoch] - no_avgs[epoch])\n",
    "        if VERBOSE: print 'Avg Difference:', diff_avgs[epoch]\n",
    "\n",
    "        diff_meds.append(yes_meds[epoch] - no_meds[epoch])\n",
    "        if VERBOSE: print 'Median Difference:', diff_meds[epoch]\n",
    "\n",
    "        topk_acc.append(top_acc(zipped_valid_input))\n",
    "        if VERBOSE: print 'Accuracy on Top', TOP_K, ':', topk_acc[epoch]\n",
    "\n",
    "    def plot_results(epoch):\n",
    "        '''\n",
    "            Plots the results vs the epochs\n",
    "        '''\n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(2,1, figsize = (6,12))\n",
    "\n",
    "        # PLot score differential\n",
    "        _ = ax[0].plot(range(epoch + 1), diff_avgs, label = 'Difference in Avg Score between edge and no edge')\n",
    "        _ = ax[0].plot(range(epoch + 1), diff_meds, label = 'Difference in Median Score between edge and no edge')\n",
    "        _ = ax[0].set_title('Performance Over Epochs')\n",
    "        _ = ax[0].set_xlabel('Epoch')\n",
    "        _ = ax[0].set_ylabel('Score Difference')\n",
    "\n",
    "        # On same plot plot accuracy on top k\n",
    "        ax2 = ax[0].twinx()\n",
    "        _ = ax2.plot(range(epoch + 1), topk_acc, 'r', label = 'Accuracy on Top %s' % TOP_K)\n",
    "        _ = ax2.set_ylabel('Accuracy')\n",
    "        lg1 = ax2.legend(loc='center left', bbox_to_anchor=(1.25, 0.1))\n",
    "        lg2 = ax[0].legend(loc='center left', bbox_to_anchor=(1.25, 0.5))\n",
    "\n",
    "        if ADD_LOG: \n",
    "            ext = \"Log \"\n",
    "        else:\n",
    "            ext = \"\"\n",
    "\n",
    "        # On second plot plot loss\n",
    "        _ = ax[1].plot(range(epoch + 1), valid_losses, label = 'Avg Validation %sLoss' % ext)\n",
    "        _ = ax[1].plot(range(epoch + 1), train_losses, label = 'Avg Training %sLoss' % ext)\n",
    "        _ = ax[1].set_xlabel('Epoch')\n",
    "        _ = ax[1].set_ylabel(\"%sLoss\" % ext)\n",
    "        lg3 = ax[1].legend(loc='center left', bbox_to_anchor=(1.25, 0.5))\n",
    "        \n",
    "        plt.savefig('plots/MF_LINK_%s_LOSS_%s_K_%d_LAMBDAU_%f_RANKING.png' % (link_name, loss_name, k, lambdaU), bbox_extra_artists=(lg1,lg2,lg3), bbox_inches='tight')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print_status(0)\n",
    "\n",
    "    # SGD\n",
    "    for epoch in range(1, N_EPOCH+1):\n",
    "\n",
    "        # Shuffle the training values\n",
    "        np.random.shuffle(o_plus)\n",
    "        np.random.shuffle(o_minus)\n",
    "    \n",
    "        # Iterate through possible edges and update parameters\n",
    "        to_iter = range(n_pos)\n",
    "        if VERBOSE:\n",
    "            to_iter = tqdm(to_iter)\n",
    "\n",
    "        for _ in to_iter:\n",
    "            for _ in range(n_neg):\n",
    "                (i,j), _  = o_plus[np.random.randint(n_plus)]\n",
    "                (ip,jp), _  = o_minus[np.random.randint(n_min)]\n",
    "                \n",
    "                eij = score(i,j, ip, jp) - 1.\n",
    "                U[i] -= gammaU*(eij*U[j] + lambdaU*U[i])\n",
    "                U[j] -= gammaU*(eij*U[i] + lambdaU*U[j])\n",
    "                B[i] -= gammaU*eij\n",
    "                B[j] -= gammaU*eij\n",
    "                \n",
    "                U[ip] -= gammaU*(-eij*U[jp] + lambdaU*U[ip])\n",
    "                U[jp] -= gammaU*(-eij*U[ip] + lambdaU*U[jp])\n",
    "                B[ip] -= gammaU*-eij\n",
    "                B[jp] -= gammaU*-eij\n",
    "\n",
    "        if VERBOSE and PLOT: \n",
    "            # Clear the display\n",
    "            display.clear_output(wait=True)\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Print out the results of the epoch\n",
    "        print_status(epoch)\n",
    "        \n",
    "        if PLOT:\n",
    "            # Plot and saves results\n",
    "            plot_results(epoch)\n",
    "\n",
    "        if VERBOSE and PLOT: \n",
    "            # Display plot\n",
    "            display.display(plt.gcf())\n",
    "    \n",
    "    results[lambdaU] = {}\n",
    "    \n",
    "    results[lambdaU]['U'] = U.copy()\n",
    "    results[lambdaU]['B'] = B.copy()\n",
    "    results[lambdaU]['train_losses'] = train_losses[:]\n",
    "    results[lambdaU]['valid_losses'] = valid_losses[:]\n",
    "    results[lambdaU]['no_avgs'] = no_avgs[:]\n",
    "    results[lambdaU]['no_meds'] = no_meds[:]\n",
    "    results[lambdaU]['yes_avgs'] = yes_avgs[:]\n",
    "    results[lambdaU]['yes_meds'] = yes_meds[:]\n",
    "    results[lambdaU]['diff_avgs'] = diff_avgs[:]\n",
    "    results[lambdaU]['diff_meds'] = diff_meds[:]\n",
    "    results[lambdaU]['topk_acc'] = topk_acc[:]\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
