{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfarrell/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1069: UserWarning: Bad val \"$TEMPLATE_BACKEND\" on line #38\n",
      "\t\"backend      : $TEMPLATE_BACKEND\n",
      "\"\n",
      "\tin file \"/Users/michaelfarrell/.matplotlib/matplotlibrc\"\n",
      "\tKey backend: Unrecognized backend string \"$template_backend\": valid strings are [u'pgf', u'cairo', u'MacOSX', u'CocoaAgg', u'gdk', u'ps', u'GTKAgg', u'nbAgg', u'GTK', u'Qt5Agg', u'template', u'emf', u'GTK3Cairo', u'GTK3Agg', u'WX', u'Qt4Agg', u'TkAgg', u'agg', u'svg', u'GTKCairo', u'WXAgg', u'WebAgg', u'pdf']\n",
      "  (val, error_details, msg))\n",
      "/Users/michaelfarrell/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import urllib\n",
    "import time\n",
    "import feedparser\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy.misc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category = 'astro-ph'\n",
    "entries = pickle.load(open(category + '_entries.pkl', 'rb'))\n",
    "author_ind = pickle.load( open(category + '_author_ind.pkl', 'rb'))\n",
    "train_adj_list = pickle.load(open(category + '_train_adj_list.pkl', 'rb'))\n",
    "test_adj_list = pickle.load(open(category + '_test_adj_list.pkl', 'rb'))\n",
    "train_adj_list_w_year = pickle.load( open( category + '_train_adj_list_with_year.pkl'))\n",
    "test_adj_list_w_year = pickle.load( open( category + '_test_adj_list_with_year.pkl'))\n",
    "\n",
    "num_authors = len(author_ind)\n",
    "authors = range(num_authors)\n",
    "pos_edges = set([(min(a1, a2), max(a1, a2)) for (a1, a2) in \\\n",
    "                 itertools.combinations(authors, 2)]) - set(train_adj_list)\n",
    "pred_edges = set(test_adj_list) - set(train_adj_list)\n",
    "\n",
    "train_years = sorted(list(set(map(lambda x : x[2], train_adj_list_w_year))))\n",
    "test_years = sorted(list(set(map(lambda x : x[2], test_adj_list_w_year))))\n",
    "possible_edges = list(itertools.combinations(authors, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the edges up by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges_by_year = {}\n",
    "for year in test_years:\n",
    "    edges_by_year[year] = map(lambda y: y[:2], filter(lambda x : x[2] == year, test_adj_list_w_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 1358)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1997, 2250)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1998, 5716)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1999, 4751)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2000, 4889)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2001, 2948)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in test_years:\n",
    "    year, len(edges_by_year[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1996, 1997, 1998]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_for_train = train_years[:3]\n",
    "valid_year = train_years[3]\n",
    "years_for_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the set of edges in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = set()\n",
    "for year in years_for_train:\n",
    "    train = train.union(set(edges_by_year[year]))\n",
    "n_train = len(train)\n",
    "n_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all potential edges with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = map(lambda x : int(x in train), possible_edges)\n",
    "zipped_train_input = zip(possible_edges, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set of new edges added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4751"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = set(edges_by_year[valid_year]).difference(train)\n",
    "n_valid = len(valid)\n",
    "n_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The set of edges to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "potential_new_edges = set(map(lambda  y : y[0], filter(lambda x: x[1] == 0, zipped_train_input)))\n",
    "zipped_valid_input = map(lambda x : (x, 1) if x in valid else (x,0), potential_new_edges)\n",
    "valid_no_edges = filter(lambda x: x[1] == 0, zipped_valid_input)\n",
    "valid_yes_edges = filter(lambda x: x[1] == 1, zipped_valid_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10 # Number of latent features\n",
    "gammaU = 1e-3\n",
    "gammaB = 1e-3\n",
    "lambdaU = 1e-1\n",
    "TOP_K = 4751\n",
    "U = np.random.rand(num_authors,k) # User matrix\n",
    "B = np.random.rand(num_authors) # Bias matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(vals):\n",
    "    return np.sum(map(lambda ((i,j), t) : (np.dot(U[i], U[j]) + B[i] + B[j] - t)**2, vals)) / len(vals) + lambdaU*np.linalg.norm(U, ord='fro')\n",
    "def predict(vals):\n",
    "    return map(lambda ((i,j), t) : np.dot(U[i], U[j]) + B[i] + B[j], vals)\n",
    "def top_acc(vals):\n",
    "    predictions = predict(vals)\n",
    "    valid_pred_vs_target = zip(predictions, map(lambda x : x[1], vals))\n",
    "    sorted_scores = sorted(valid_pred_vs_target, key= lambda  x: x[0], reverse=True)\n",
    "    return len(filter(lambda x : x[1] == 1, sorted_scores[:TOP_K]))/float(TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_U = np.zeros((num_authors, k, k)) +.01\n",
    "G_B = np.zeros(num_authors) + .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "valid score: 21.956335614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "valid score: 15.3456495715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2\n",
      "valid score: 13.4708512796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 49431/3272961 [00:02<02:47, 19222.73it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ba4792469cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meij\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambdaU\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mG_U\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgammaU\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_U\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_scores = []\n",
    "train_scores = []\n",
    "no_scores = []\n",
    "yes_scores = []\n",
    "top_k_acc = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_EPOCH = 25\n",
    "for epoch in range(N_EPOCH):\n",
    "#     gammaU *= .1\n",
    "#     gammaB *= .1\n",
    "    print 'EPOCH', epoch\n",
    "#     print 'train score:', score(zipped_train_input)\n",
    "    print 'valid score:', score(zipped_valid_input)\n",
    "#     print 'no avg score:', np.mean(predict(valid_no_edges)), 'yes avg score:', np.mean(predict(valid_yes_edges))\n",
    "#     print 'Acc of TOP ', TOP_K, ':', top_acc(zipped_valid_input)\n",
    "    np.random.shuffle(zipped_train_input)\n",
    "    for (i,j), target in tqdm(zipped_train_input):\n",
    "        # Difference in prediction vs target\n",
    "        eij = np.dot(U[i], U[j]) + B[i] + B[j] - target\n",
    "        \n",
    "        gi = (eij*U[j] + lambdaU*U[i])\n",
    "        G_U[i] += np.outer(gi, gi)\n",
    "        U[i] -= gammaU*np.multiply(np.diag(G_U[i])**(-.5), gi)\n",
    "        \n",
    "        gj = (eij*U[i] + lambdaU*U[j])\n",
    "        G_U[j] += np.outer(gj, gj)\n",
    "        U[j] -= gammaU*np.multiply(np.diag(G_U[j])**(-.5), gj)\n",
    "        \n",
    "        sq_eij = eij**2\n",
    "        \n",
    "        G_B[i] += sq_eij\n",
    "        B[i] -= gammaB*eij/np.sqrt(G_B[i])\n",
    "        \n",
    "        G_B[j] += sq_eij\n",
    "        B[j] -= gammaB*eij/np.sqrt(G_B[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.outer(U[1], U[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
